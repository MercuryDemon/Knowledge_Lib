18-12-2025 20:43
Tags: #z #DB #lesson
# Kafka - брокер сообщений

Кафка - распределенный брокер сообщений в стриминговом режиме. 

- Прилетает сообщения , их надо обработать и какойто части приложения передать.
- Master - slave система, есть одна сущность которая командует подчиненными сущностями.
## Основные свойства

- рспределенная система (не обин сервер, а несколько серверов)
- отказаустойчивая система
- высокая доступность и согласованность данных
- Обеспечивает высокую производительность
- простая горизонтальная массштабируемость

## Решаемые задачи

Существуют несколько типов сообщений, их Producers(производители) и Cunsumers(потребители). При таком взаимодействии возникают сложности.
Кафка позволяет принимать, обрабатывать входящие сообщения и распределять по потребителям. 
![[Pasted image 20251218205323.png]]

Кафка это БРОКЕР(посредник)
![[Pasted image 20251218205649.png]]

- в брокере есть "ящики" для нескольких типов сообщений, он изх туда принимает, а потребители сами забирают нужные им сообщения из брокера.

удобства:
- надёжность и гарантия доставки
- простое подключение новых получателей
- отправители отвязаны (ничего не знают о получателях) от получателей
- простая тех поддержка
- интеграция разных стеков


## Основные сущности Kafka

### Broker

- Кафка сервер, кафка Нод - алиасы

Функции: 
- приём сообщений
- Хранение сообщений
- Выдача сообщений

Брокеров может быть много, они между собоц общаются сознавая Kafka Cluster

Кафка кластер реализует: 
- Масштабирование
- Репликацию


### Zookeeper

Zookeeper - инструмент, координатор кластера.

- По сути БД, которая хранит конфигурацию и метаданные кластера
- быстро работает на чтение, медленно на запись
![[Pasted image 20251218210942.png]]

Что хранит:
- Состояние кластера
- Конфигурацию
- Адресную книгу(где расположены брокеры)
- Выбор Controller
- Сам контроллер

Kafka controller - один специальный брокеров, который обеспечивает консистентность данных


### Message(Record)

![[Pasted image 20251218211644.png]]
Сообщение представляет из себя Key - value пару. 
- Ключ необязателен, он необходим для распределения сообщений по кластеру. 
- Value - это бизнес банные.



### Topic/Partition

Topic - Основная сущность Kafka. Предстваяляет из себя поток данных. 
Труба с очередью для входящих сообщений. 

![[Pasted image 20251218212038.png]]
![[Pasted image 20251218212209.png]]
- Очередь в топике организована по принципу **FIFO**.

- Данные из топиков не удаляются, а остаются в нем, для считывания разными потребителями

Для ускорения чтения/записи данных топик разбивается на партиции(**PARTITIONS**).
- Партиции - конфигурируемый параметр

![[Pasted image 20251218212658.png]]
Данные считываются неупорядоченно из топика, но упорядоченно относительно портиции из которой читаем.

#### Расположение Топиков по брокерам

Партиции топика могут быть разнесены по нескольким брокерам.
![[Pasted image 20251218213627.png]]
Это сделано для баллансирования нагрузки между брокерами.

Одновременно с этим несколько топиков могут быть распределены между разными броокерами.
![[Pasted image 20251218213541.png]]

- Это всё можно конфигурировать вручную

#### Где хранятся данные из топиков

- Данне хранятся в Логах)))

структура данных такая
![[Pasted image 20251218221915.png]]


- Логи сегментированы, один сегмент - лог файл 1 Гб 
- одновременно активен только один сегмент. 
- у каждого сегмента тоже есть таймстемп


#### Удаление данных из топиков.

- Операция удаления данных не поддерживается
- Поддерживается автоматическое удление данных по TTL (time to live)
- Удаляются целиком сегменты


#### Data Replication

- Обеспечение надежности данных и отказоустойчивости

Может случится ситуация, когда один из брокеров отваливается. В таком случае все данные из расположенных на нем партиций ториков пропадают. Чтобы этого не происходило партиции реплицируются на другие брокеры.

**Set replication-factor (>1)** - надстройка при создании топиков. Сколько реплик каждой портиции создавать.

В случае репликации партиций, они разделяются на LEADER(главную) и FOLOWER(догоняющую).
- чтение/запись только с ЛИДЕР реплики.

- Фоловеры сами опрашивают  лидера для обновления у себя данных.
- есть реплики синхранизированные мгновенно (ISR Replica). Для того чтобы не проебать сообщение если лидер отвалится.
min.insync.replias = n-1 (на единицу меньше всех реплик)

### Producer

Kafka Producer - высокопроизводительный отправитель сообщений.
![[Pasted image 20251218224152.png]]
- acks = 0, продюьсер не ждет от брокера подтверждение отправки сообщения (самый ненадёжный режим, сообщения могут проебаться)
- acks = 1, ждёт подтверждения только от ЛИДЕР реплики (данные могулт проебаться, если брокер с лидер репликой упал, до реплицирования сообщений)
- acks = -1, ждёт подтверждения от всех ISR-реплик

Семантика доставки определяет:
- at most once - не облее одного сообщения отправится
- at least once - не менее одного сообщения отправится
- exactly once - отправится ровно одно сообщение

Метод **Send** под капотом:

1. Fetch metadata - получение метаданных из zookeeper (из чего состоит кластер, где какие реплики, какие из них лидеры)
![[Pasted image 20251226204135.png]]
продюсер кэширует метаданные и при отправке следующего сообщения использует их, а не fetch-ит заново.

2. serialize message - приводит данные в сообщения к определенному типу 

3. define partition - определяет в какую партицию отправлять
варианты:
- explicit pertition - определенная партитция
- round-robin - сам разберись какая партиция (0, 1, 2, 3  партиция и так по кругу)
- key-defined (key_hash % n) - выбор партиции по хэшу ключа, для хэширования используется MurmurHash2

4. Compress message - сообщение сжимается разными кодэками (например zip)

5. Accumulate batch - копим партию сообщений (количество сообщений в партии определяется параметром batch.size. Также есть параметр linger.ms, чтобы отправлять сообщение через какое-то время, если батч сайз долго не удается привысить)

6. Непосредственно отправка батчей(партий) сообщений на разные брокеры в нужные партиции

### Consumer

#### Метод **poll massages** под капотом:

1. Fetch metadata - получение метаданных из zookeeper (cluster state, topic placement)

2. Подключение к **Leader**-репликам всех партиций топика.

можно запустить несколько  consumer - получится consumer group
![[Pasted image 20251226210332.png]]
- нужно  чтобы распараллелить получение сообщений он лидер-реплик всех партиций в топике. Один консюмер на одну партицию.

#### Kafka Consumer Offset

consumer - получает пачку сообщений, если консюмер обработает эти сообщения, а потом ляжет, другой консюмер получит заново те же сообщения. Чтобы не обрабатывать одни и теже сообщения при сбоях консюмера, в Кафка в каждом брокере есть отдельный топик, "`__customer_offsets`", в нем хранятся офсеты для каждой пачки сообщений. А также есть система коммитов.

Commit сообщениесостоит из полей:
- партиция - название топика/номер партиции
- Группа - название группы
- Оффсет(сдвиг) - сколько сообщений обработаны.

![[Pasted image 20251226211703.png]]

Когда консюмер обрабатывает сообщение он отправляет commit сообщение в `__customer_offsets` топик брокера.

Если этот консюмер отвалится после обработки, следущий консюмер сначала читает информацию из `__customer_offsets` топика, а потом получает пачку сообщений с оффсетом.

Типы commit - ов:
1. auto commit - как только консюмер получил пачку сообщений **но не успел обработать**, сразу коммитит. Подходит если не боимся потерять сообщения. (так реализуется at most once)

2. manual commit - коммит отправляется после обработки **всей** пачки сообщений. Возможно дублирование сообщений. (так реализуется at least once)

3. Custom offset managment. Храним оффсеты где-то у себя, коммитим после каждого обработанного сообщения. Нет дублей и нет потерь сообщений. (так реализуется exactly once) 


### Zero-Links
- [[00 Обучение]]
- [[00 Data_Base]]


### Links
- https://www.youtube.com/watch?v=-AZOi3kP9Js

